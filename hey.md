# 🤟 American Sign Language Detection – Detailed Project Report

## 📌 Project Objective

The primary goal of this project is to build an image classification system capable of detecting American Sign Language (ASL) alphabets from static hand gesture images. The model is trained on a publicly available dataset using Convolutional Neural Networks (CNN) and tested on real input images. The final system is capable of recognizing 29 ASL gestures including the English alphabets A-Z and three special signs: `space`, `delete`, and `nothing`.

---

## 🧾 Project Overview

- **Problem Statement**: Automatically classify ASL hand signs from image data.
- **Approach**: Supervised image classification using deep learning (CNN).
- **Tools Used**:
  - Python
  - TensorFlow / Keras
  - OpenCV
  - Matplotlib / NumPy
- **Dataset**: `asl_alphabet_train` (training set with 87000+ images) and `asl_alphabet_test` (29 images, one per class for testing).

---

## 📁 Directory Structure

